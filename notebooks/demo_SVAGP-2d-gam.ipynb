{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Additive Regression \n",
    "$$f_c \\sim \\cal{GP}(0,k_c),\\; \\forall c \\in [1..C]$$\n",
    "$$y^{(n)}|f_1...f_C,x^{(n)} = y^{(n)}|\\sum_c f_c(x^{(n)}_c)$$\n",
    "\n",
    "Functions $f_c$ are all functions of separate covariates $x_c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.contrib.opt import ScipyOptimizerInterface as soi\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Simulating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lik = 'Poisson'\n",
    "#lik = 'Gaussian'\n",
    "assert lik in ['Poisson','Gaussian']\n",
    "\n",
    "#---------------------------------------------------\n",
    "# Declaring additive GP model parameters\n",
    "N =500\n",
    "D = 4 # covariates dimension\n",
    "R = 1 # number of trials\n",
    "f_indices = [[0],[1,2],[3]]\n",
    "C = len(f_indices) # number of latent functions\n",
    "scale = 2.\n",
    "fs = [lambda x:np.sin(x)**3*scale, \n",
    "      lambda x: (np.sin(x[:,0])*np.sin(x[:,1])).reshape(-1,1)*scale ,\n",
    "     lambda x:np.cos(x)*scale]\n",
    "#---------------------------------------------------\n",
    "# Simulating data\n",
    "xmin,xmax=-3,3\n",
    "X_np = np.random.uniform(xmin,xmax,(N,D))\n",
    "F_np = np.hstack([fs[d](X_np[:,f_indices[d]]) for d in range(C)])\n",
    "pred_np = np.sum(F_np,axis=1,keepdims=True)\n",
    "\n",
    "if lik == 'Gaussian':\n",
    "    Y_np = pred_np + np.random.randn(N,R)*.5\n",
    "elif lik=='Poisson':\n",
    "    link = np.exp\n",
    "    rate = np.tile(link(pred_np),[1,R])\n",
    "    Y_np = np.random.poisson(rate,size=(N,R))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors_c = plt.cm.winter(np.linspace(0,1,C))\n",
    "fig,ax = plt.subplots(1,C,figsize=(C*4,4))\n",
    "for c in range(C):\n",
    "    i = f_indices[c]\n",
    "    if len(f_indices[c])==1:\n",
    "        o = np.argsort(X_np[:,f_indices[c]],0)\n",
    "        ax[c].plot(X_np[o,i],F_np[o,c],'-',color=colors_c[c])\n",
    "        ax[c].set_xlabel('$x_%d$'%i[0],fontsize=20)\n",
    "        ax[c].set_ylabel('$f_%d(x_%d)$'%(i[0],i[0]),fontsize=20)\n",
    "    elif len(f_indices[c])==2:\n",
    "        ax[c].scatter(X_np[:,i[0]],\n",
    "                      X_np[:,i[1]],\n",
    "                      c=F_np[:,c],linewidth=0)\n",
    "        ax[c].set_xlabel('$x_%d$'%i[0],fontsize=20)\n",
    "        ax[c].set_ylabel('$x_%d$'%i[1],fontsize=20)\n",
    "        ax[c].set_title('$f(x_%d,x_%d)$'%(i[0],i[1]),fontsize=20)\n",
    "plt.suptitle('True underlying functions',y=1.05,fontsize=20)   \n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Constructing tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../SVAGP')\n",
    "from kernels import RBF\n",
    "from likelihoods import Gaussian, Poisson, Gaussian_with_link\n",
    "from settings import np_float_type,int_type\n",
    "from model import SVAGP\n",
    "\n",
    "#---------------------------------------------------\n",
    "# Constructing tensorflow model\n",
    "\n",
    "X = tf.placeholder(tf.float32,[N,D])\n",
    "Y = tf.placeholder(tf.float32,[N,R])\n",
    "ks,Zs = [],[]\n",
    "\n",
    "ks =[]\n",
    "with tf.variable_scope(\"kernels\") as scope:\n",
    "    for c in range(C):\n",
    "        with tf.variable_scope(\"kernel%d\"%c) as scope:\n",
    "            input_dim = len(f_indices[c])\n",
    "            ks.append(  RBF(input_dim,lengthscales=.5*np.ones(input_dim),  variance=1.))    \n",
    "    \n",
    "with tf.variable_scope(\"likelihood\") as scope:\n",
    "    if lik=='Gaussian':\n",
    "        likelihood = Gaussian(variance=1)\n",
    "    elif lik == 'Poisson':\n",
    "        likelihood = Poisson()\n",
    "    \n",
    "with tf.variable_scope(\"ind_points\") as scope:\n",
    "    for c in range(C):\n",
    "        with tf.variable_scope(\"ind_points%d\"%c) as scope:\n",
    "            input_dim = len(f_indices[c])\n",
    "            Z_ = np.random.uniform(xmin,xmax,[20,input_dim]).astype(np_float_type)\n",
    "            Zs.append(   tf.Variable(Z_,tf.float32,name='Z') )\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"model\") as scope:\n",
    "    m= SVAGP(X,Y,ks,likelihood,Zs,q_diag=True,f_indices=f_indices)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running inference and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------------------------------\n",
    "\n",
    "sess  = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # reset values to wrong\n",
    "# declare loss\n",
    "loss = -m.build_likelihood()\n",
    "# separate variables\n",
    "vars_e, vars_m, vars_h, vars_z= [], [], [], []\n",
    "vars_e += tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='model/inference')\n",
    "if lik=='Gaussian':\n",
    "    vars_m += tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='likelihood')\n",
    "vars_z += tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='ind_points')\n",
    "vars_h += tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='kernels')\n",
    "# declare optimizers\n",
    "opt_e = soi(loss, var_list=vars_e,  method='L-BFGS-B', options={'ftol': 1e-4})\n",
    "opt_m = soi(loss, var_list=vars_m,  method='L-BFGS-B', options={'ftol': 1e-4})\n",
    "opt_z = soi(loss, var_list=vars_z,  method='L-BFGS-B', options={'ftol': 1e-4})\n",
    "opt_h = soi(loss, var_list=vars_h,  method='L-BFGS-B', options={'ftol': 1e-2})\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) # reset values to wrong\n",
    "feed_dic = {Y:Y_np, X:X_np}\n",
    "\n",
    "#---------------------------------------------------\n",
    "\n",
    "\n",
    "print('Optimized variables:')\n",
    "for var in vars_e+vars_z+vars_h:\n",
    "    print(var.name)  # Prints the name of the variable alongside its val\n",
    "\n",
    "nit = 30\n",
    "loss_array = np.zeros((nit,))\n",
    "\n",
    "\n",
    "# declare which optimization to perform\n",
    "\n",
    "OPT = ['E','Z','H']\n",
    "if lik=='Gaussian':\n",
    "    OPT.append('M')\n",
    "    \n",
    "# Optimization is performed using L-BFGS-B, iterating over different subsets of variable\n",
    "# - E: inference (as in classical EM)\n",
    "# - Z: update of inducing point locations\n",
    "# - H: kernel hyperparameter optimization\n",
    "\n",
    "print('Starting Optimization')\n",
    "opt_e.minimize(sess, feed_dict=feed_dic)\n",
    "if 'E' in OPT:\n",
    "    opt_e.minimize(sess, feed_dict=feed_dic)\n",
    "if 'H' in OPT:\n",
    "    opt_h.minimize(sess, feed_dict=feed_dic)\n",
    "\n",
    "for it in range( nit):\n",
    "    if 'E' in OPT:    \n",
    "        opt_e.minimize(sess, feed_dict=feed_dic)\n",
    "    if 'M' in OPT:    \n",
    "        opt_m.minimize(sess, feed_dict=feed_dic)\n",
    "    if 'Z' in OPT:\n",
    "        opt_z.minimize(sess, feed_dict=feed_dic)\n",
    "    if 'H' in OPT:\n",
    "        opt_z.minimize(sess, feed_dict=feed_dic)\n",
    "\n",
    "    loss_array[it]= float(sess.run(loss, feed_dic))\n",
    "\n",
    "Fs_mean,Fs_var = sess.run(m.build_predict_fs(X),  feed_dic)\n",
    "pred_mean,pred_var = sess.run(m.build_predict_additive_predictor(X),  feed_dic)\n",
    "Zs = sess.run(m.Zs,  feed_dic)\n",
    "\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig,axarr = plt.subplots(1,2,figsize=(8,4))\n",
    "ax=axarr[0]\n",
    "ax.plot(loss_array[:it], linewidth=3, color='blue')\n",
    "ax.set_xlabel('iterations',fontsize=20)\n",
    "ax.set_ylabel('Variational Objective',fontsize=20)\n",
    "ax=axarr[1]\n",
    "ax.errorbar(pred_mean,pred_np,yerr=np.sqrt(pred_var), \n",
    "            elinewidth = 1, fmt='.', color='blue', alpha=.1)\n",
    "ax.plot(pred_mean,pred_np,'.',color='blue')\n",
    "ax.plot([pred_mean.min(),pred_mean.max()],\n",
    "        [pred_mean.min(),pred_mean.max()],\n",
    "        '--',linewidth=2,color='grey')\n",
    "ax.set_xlabel('True predictor',fontsize=20)\n",
    "ax.set_ylabel('Predicted predictor',fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,C,figsize=(C*5,5))\n",
    "for c in range(C):\n",
    "    i = f_indices[c]\n",
    "    if len(i)==1:\n",
    "        o = np.argsort(X_np[:,i],0)\n",
    "        f,s =  Fs_mean[c,:,0],np.sqrt(Fs_var[c,:,0])\n",
    "        ax[c].vlines(Zs[c],ymin=f.min(),ymax=f.max(),alpha=.05,color=colors_c[c])\n",
    "        ax[c].plot(X_np[o,i],f[o],color=colors_c[c])\n",
    "        ax[c].fill_between(X_np[o,i].flatten(),\n",
    "                           (f-s)[o].flatten(),\n",
    "                           y2=(f+s)[o].flatten(),\n",
    "                           alpha=.1,facecolor=colors_c[c])\n",
    "        ax[c].plot(X_np[o,i],F_np[o,c],'--',color=colors_c[c])\n",
    "        ax[c].set_xlabel('$x_%d$'%i[0],fontsize=20)\n",
    "        ax[c].set_ylabel('$f_%d(x_%d)$'%(i[0],i[0]),fontsize=20)\n",
    "\n",
    "    elif len(f_indices[c])==2:\n",
    "        ax[c].scatter(X_np[:,i[0]],\n",
    "                      X_np[:,i[1]],\n",
    "                      c=Fs_mean[c,:,0],linewidth=0)\n",
    "        ax[c].scatter(Zs[c][:,0],Zs[c][:,1],\n",
    "                      c='r', marker=(5, 1))\n",
    "        ax[c].set_xlabel('$x_%d$'%i[0],fontsize=20)\n",
    "        ax[c].set_ylabel('$x_%d$'%i[1],fontsize=20)\n",
    "        ax[c].set_title('$f(x_%d,x_%d)$'%(i[0],i[1]),fontsize=20)\n",
    "plt.suptitle('Inferred underlying functions',y=1.05,fontsize=20) \n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
